{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d00c7945-8cc9-4f3c-b6d0-838ec2cd8141",
   "metadata": {},
   "source": [
    "# Partición Externa de Datos (Hold-out)\n",
    "Vamos a comenzar realizando la partición de datos externa para separar el conjunto de datos total en los subconjuntos de entrenamiento (train), y prueba (test).\n",
    "Dado que estamos ante un problema de series temporales, se requiere mantener la coherencia temporal por lo que no se aplicará un shuffle a los datos.\n",
    "Además en nuestro caso asegurar que datos de entrenamiento no se localizan entre los datos de test, no sólo se limita a las instancias individuales en sí, sino que dado que nuestro objetivo será predecir si en un cierto año y para un determinado país se está ante una posible situación de pre-crisis, también tenemos que asegurar que no existe información relativa a años posteriores en nuestro conjunto de test ni para el país bajo estudio en concreto ni tampoco para otros paises (Hellwig, K.P. (2021). Predicting Fiscal Crises: A Machine Learning Approach), por lo que particionaremos el dataset a partir de un año concreto manteniendo los valores más cercanos a una distribución de porcentajes igual al 80% para datos de entrenamiento y 20% para datos de prueba.\n",
    "\n",
    "Un punto importante a tener en cuenta es que en nuestro dataset siempre hay un registro asociado a cada país y año, por lo que podemos calcular el año a partir del cual particionar en base a esta información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4df9098d-2e89-4492-8a3e-eef49e3ef044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2873ca65-2e00-4e75-bb33-920f88cea2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número Total de Países: 188\n",
      "Número Total de Años: 46\n",
      "Año de Particionado: 2007\n",
      "Muestras de Entrenamiento: (6956, 105) -- 80.43% del total\n",
      "Muestras de Test: (1692, 105) -- 19.57% del total\n",
      "Distribución de Muestras:\n",
      "\tEntrenamiento: ['No Crisis', 'Pre-Crisis', 'Crisis/Post-Crisis'] - [3593 1006 2357]\n",
      "\tTest: ['No Crisis', 'Pre-Crisis', 'Crisis/Post-Crisis'] - [953 208 531]\n"
     ]
    }
   ],
   "source": [
    "# Cargamos nuestro dataset\n",
    "data = pd.read_csv('../datasets/DatasetLimpio.csv', sep=';', na_values='', decimal=',')\n",
    "\n",
    "# Calculamos el número del registro a partir del cual particionar\n",
    "pct_train = 0.8\n",
    "\n",
    "num_paises = len(np.unique(data['Country']))\n",
    "print(f'Número Total de Países: {num_paises}')\n",
    "\n",
    "num_anios = len(np.unique(data['Year']))\n",
    "print(f'Número Total de Años: {num_anios}')\n",
    "\n",
    "anio_particion = np.min(data['Year']) + round(num_anios*pct_train)\n",
    "print(f'Año de Particionado: {anio_particion}')\n",
    "\n",
    "train = data[data['Year'] < anio_particion]\n",
    "test = data[data['Year'] >= anio_particion]\n",
    "\n",
    "print(f'Muestras de Entrenamiento: {train.shape} -- {train.shape[0] * 100 / data.shape[0]:.2f}% del total')\n",
    "print(f'Muestras de Test: {test.shape} -- {test.shape[0] * 100 / data.shape[0]:.2f}% del total')\n",
    "\n",
    "etiquetas = ['No Crisis', 'Pre-Crisis', 'Crisis/Post-Crisis']\n",
    "_, ocurrencias_train = np.unique(train['Crisis'], return_counts=True)\n",
    "_, ocurrencias_test = np.unique(test['Crisis'], return_counts=True)\n",
    "print(f'Distribución de Muestras:\\n\\tEntrenamiento: {etiquetas} - {ocurrencias_train}\\n\\tTest: {etiquetas} - {ocurrencias_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f5a4c8a-313f-456e-8794-60c1626e04f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardo las particiones\n",
    "import os\n",
    "if not os.path.exists('../particiones'):\n",
    "    os.mkdir('../particiones')\n",
    "\n",
    "train.to_csv('../particiones/train_original.csv', sep=';', na_rep='', decimal=',', index=False)\n",
    "test.to_csv('../particiones/test_original.csv', sep=';', na_rep='', decimal=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
